# Res2Fusion: Infrared and visible image fusion based on dense Res2net and double nonlocal attention models
Zhishe Wang, Yuanyuan Wu, Junyao Wang, Jiawei Xu, Wenyu Shao

[paper](https://ieeexplore.ieee.org/document/9670874)  

## Platform
Python 3.7  
Pytorch >=1.6.0  

## Training Dataset

[MS-COCO 2014](http://images.cocodataset.org/zips/train2014.zip) (T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Dollar, and C. L. Zitnick. Microsoft coco: Common objects in context. In ECCV, 2014. 3-5.) is utilized to train our auto-encoder network.


## Citation
If this work is helpful to you, please cite it as:
```
@ARTICLE{9670874,
  author={Wang, Zhishe and Wu, Yuanyuan and Wang, Junyao and Xu, Jiawei and Shao, Wenyu},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={Res2Fusion: Infrared and visible image fusion based on dense Res2net and double non-local attention models}, 
  year={2022},
  volume={},
  number={},
  pages={1-1},
  doi={10.1109/TIM.2021.3139654}}
  
```
If you have any question, please email to me (wangzs@tyust.edu.cn).
